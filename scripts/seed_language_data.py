import json
import logging
import sys
from pathlib import Path

from sqlalchemy.orm import Session
from tqdm import tqdm

# --- Configuration du chemin et des imports ---
# Ajoute le r√©pertoire parent au path pour permettre les imports relatifs de l'application
sys.path.append(str(Path(__file__).resolve().parents[1]))

# --- SOLUTION: Importer la base et TOUS les mod√®les ici ---
# Cette √©tape est CRUCIALE. Elle charge tous les mod√®les dans les m√©tadonn√©es de SQLAlchemy
# avant que nous n'essayions d'interagir avec la base de donn√©es, r√©solvant ainsi les
# erreurs de "failed to locate a name".
from app.db.base import Base
from app.models.user.user_model import User
from app.models.capsule.capsule_model import Capsule
from app.models.analytics.vector_store_model import VectorStore
# Ajoutez d'autres imports de mod√®les si n√©cessaire pour couvrir toutes les relations
# --- Fin de la solution ---

from app.db.session import SessionLocal
from app.services.rag_utils import get_embedding


# --- Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Liste des fichiers de donn√©es √† traiter
DATA_FILES = [
    Path(__file__).resolve().parent.parent / "app" / "data" / "langues" / "kana.jsonl",
    Path(__file__).resolve().parent.parent / "app" / "data" / "langues" / "kanjis.jsonl",
    Path(__file__).resolve().parent.parent / "app" / "data" / "langues" / "vocabulaire.jsonl",
]

# --- Fonctions de Pr√©paration du Texte ---

def format_kana_for_embedding(item):
    """Cr√©e une phrase descriptive pour un kana."""
    data = item.get('data', {})
    return f"Caract√®re japonais {data.get('script', '')} : {data.get('character', '')}, prononc√© {data.get('romaji', '')}."

def format_kanji_for_embedding(item):
    """Cr√©e une phrase descriptive pour un kanji."""
    data = item.get('data', {})
    return f"Kanji japonais : {data.get('character', '')}. Signification : {data.get('meaning', '')}. Lectures ON : {data.get('onyomi_romaji', '')}, Lectures KUN : {data.get('kunyomi_romaji', '')}."

def format_vocabulary_for_embedding(item):
    """Cr√©e une phrase descriptive pour un mot de vocabulaire."""
    data = item.get('data', {})
    example = data.get('example_sentences', [{}])[0].get('fr', '')
    return f"Mot de vocabulaire japonais : {data.get('word', '')} ({data.get('reading', '')}). Signification : {data.get('meaning', '')}. Exemple : {example}"

# Mapping entre le type de contenu et la fonction de formatage
CONTENT_TYPE_FORMATTERS = {
    "kana": format_kana_for_embedding,
    "kanji": format_kanji_for_embedding,
    "vocabulary": format_vocabulary_for_embedding
}

# --- Script Principal ---

def seed_language_course_material():
    """
    Script principal pour lire les fichiers JSONL de cours de langue, cr√©er les embeddings,
    et les stocker dans la table VectorStore via SQLAlchemy.
    """
    db: Session = SessionLocal()
    try:
        logger.info("--- D√©marrage du seeding pour le mat√©riel de cours de langue ---")

        # 1. Nettoyer les anciennes entr√©es pour ce mat√©riel de cours sp√©cifique
        logger.info("Suppression des anciennes entr√©es de cours de japonais pour √©viter les doublons...")
        num_deleted = db.query(VectorStore).filter(
            VectorStore.domain == 'language_learning',
            VectorStore.area == 'japanese'
        ).delete(synchronize_session=False)
        db.commit()
        if num_deleted > 0:
            logger.warning(f"üßπ {num_deleted} anciennes entr√©es ont √©t√© supprim√©es de la table VectorStore.")

        vectors_to_add = []
        total_count = 0

        # 2. Traiter chaque fichier de donn√©es
        for file_path in DATA_FILES:
            if not file_path.exists():
                logger.warning(f"Le fichier {file_path} n'a pas √©t√© trouv√©. Passage au suivant.")
                continue

            logger.info(f"--- Traitement du fichier : {file_path.name} ---")

            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for line in tqdm(lines, desc=f"Lecture de {file_path.name}"):
                    try:
                        item = json.loads(line)
                        content_type = item.get('content_type')

                        if not item.get('doc_id') or not content_type:
                            logger.warning(f"Ligne ignor√©e (doc_id ou content_type manquant): {line.strip()}")
                            continue
                        
                        formatter = CONTENT_TYPE_FORMATTERS.get(content_type)
                        if not formatter:
                            logger.warning(f"Aucun formateur trouv√© pour le content_type '{content_type}'. Ligne ignor√©e.")
                            continue
                            
                        document_text = formatter(item)
                        embedding_vector = get_embedding(document_text)

                        new_vector = VectorStore(
                            chunk_text=document_text,
                            embedding=embedding_vector,
                            domain='language_learning',
                            area='japanese',
                            skill=content_type,
                            metadata_=item 
                        )
                        vectors_to_add.append(new_vector)
                        total_count += 1

                    except json.JSONDecodeError:
                        logger.error(f"Erreur de d√©codage JSON pour la ligne : {line.strip()}")
                    except Exception as e:
                        logger.error(f"Erreur inattendue en traitant la ligne {line.strip()}: {e}")

        # 3. Ajouter tous les nouveaux vecteurs √† la base de donn√©es en une seule fois
        if vectors_to_add:
            logger.info(f"Ajout de {len(vectors_to_add)} nouveaux vecteurs √† la base de donn√©es...")
            db.add_all(vectors_to_add)
            db.commit()
            logger.info(f"‚úÖ SUCC√àS : {total_count} documents de cours de langue ont √©t√© vectoris√©s et ajout√©s.")
        else:
            logger.info("‚ÑπÔ∏è Aucun document valide trouv√© √† ajouter.")

    except Exception as e:
        logger.error(f"‚ùå Une erreur critique est survenue durant le seeding : {e}", exc_info=True)
        db.rollback()
    finally:
        logger.info("--- Fin du script de seeding. Fermeture de la session DB. ---")
        db.close()


if __name__ == "__main__":
    seed_language_course_material()